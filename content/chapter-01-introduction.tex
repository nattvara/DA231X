\chapter{Introduction}
\label{ch:introduction}


% \sweExpl{svensk: Introduktion}
% \sweExpl{Ofta kommer problemet och problemägaren från industrin där man önskar en specifik lösning på ett specifikt problem. Detta är ofta ”för smalt” definierat och ger ofta en ”för smal” lösning för att resultatet skall vara intressant ur ett mer allmänt ingenjörsperspektiv och med ”nya” erfarenheter som resultat. Fundera tillsammans med projektets intressenter (student, problemägare och akademi) hur man skulle kunna använda det aktuella problemet/förslaget för att undersöka någon ingenjörsaspekt och vars resultat kan ge ny eller kompletterande erfarenhet till ingenjörssamfundet och vetenskapen.\\slöser man en del eller hela delen av det ursprungliga problemet.\\Erfarenheten kommer ur en frågeställning som man i examensarbetet försöker besvara med tidigare och andras erfarenhet, egna eller modifierade metoder som ger ett resultat vilket kan användas för att diskutera ett svar på undersökningsfrågan.\\Detta stycke skall alltså, förutom det ursprungliga ”smala” problemet, innehålla  vad som skall undersökas för att skapa ny ingenjörserfarenhet och/eller vetenskap.}


% \engExpl{The first paragraph after a heading is not indented, all of the
%   subsequent paragraphs have their first line indented.}


% This chapter describes the specific problem that this thesis addresses, the context of the problem, the
% goals of this thesis project, and outlines the structure of the thesis.\\


% \generalExpl{Give a general introduction to the area. (Remember to use appropriate references in this and all other sections.)}


% One can use either biblatex or bibtex - set as the option for the document at the top of this file
% \ifbiblatex
% \engExpl{We use the \emph{biblatex} package to handle our references.  We
% use the command \texttt{parencite} to get a reference in parenthesis, like
% this \textbackslash parencite\{heisenberg2015\} resulting in \parencite{heisenberg2015}.  It is also possible to include the author as part of the sentence using \texttt{textcite}, like talking about the work of \textbackslash textcite\{einstein2016\} resulting in \textcite{einstein2016}.\\
% This also means that you have to change the include files to include biblatex and change the way that the \texttt{reference.bib} file is included.}
% \else
% \engExpl{We use the \emph{bibtex} package to handle our references.  We, therefore,
% use the command \textbackslash cite\{farshin\_make\_2019\}. For example, Farshin, \etal described how to improve LLC
% cache performance in \cite{farshin_make_2019} in the context of links running
% at \qty{200}{Gbps}.}
% \fi


% \engExpl{Use the glossaries package to help yourself and your readers.
% Add the acronyms and abbreviations to lib/acronyms.tex. Some examples are shown below:}
% In this thesis, we will examine the use of \glspl{LAN}. In this thesis, we will
% assume that \glspl{LAN} include \glspl{WLAN}, such as \gls{WiFi}.




\section{Background}
\label{sec:background}


This degree project will investigate Large Language Models (\gls{LLM}) and Retrieval Augmented Generation (\gls{RAG}) systems in the form of deploying an AI-Assistant in canvas course rooms. The degree project will investigate how to evaluate these systems in very specialised domains and benchmark various models, approaches and techniques.

The reason this research is important is that LLMs have gained widespread attention and we are likely to see large-scale adoption of these models into various applications. Understanding how to benchmark and evaluate these systems in specialised domains will be crucial to understand how to build these systems, which techniques to use, and which models work well.


Many organisations need to, due to commercial and regulatory compliance, host all AI-models themselves. This aspect is also interesting to evaluate, i.e. how well open source and commercially licensed models compare against the closed source models, such as GPT-4 by OpenAI.


% \sweExpl{svensk: Bakgrund}
% \generalExpl{Present the background for the area. Set the context for your project – so that your reader can understand both your project and this thesis. (Give detailed background information in Chapter 2 - together with related work.)
% Sometimes it is useful to insert a system diagram here so that the reader
% knows what are the different elements and their relationship to each
% other. This also introduces the names/terms/… that you are going to use
% throughout your thesis (be consistent). This figure will also help you later
% delimit what you are going to do and what others have done or will do.}


\subsection{Where the research is taking place}


The research will be carried out within the e-learning management object at KTH, who are responsible for the digital learning environment at KTH. The object consists of two teams at the KTH IT department and one team at the digital learning unit at the ITM-school. The university hosts thousands of courses with domain specific information, such as 
assignments, lectures and schedules, that aren’t part of the public domain and therefore not part of the training set of LLMs.


All the work done by KTH IT aims to improve the operations at the university. Among this is reducing the administrative burden undertaken by teachers and teaching assistants (TAs). KTH IT wants to investigate if AI-assistants can be deployed into the canvas course rooms to reduce the workload of teachers and TAs which would help them focus on teaching, helping students and improve the quality of the education. KTH IT wants to see if it’s feasible to deploy an AI assistant into the canvas course rooms.


\section{Problem}
\label{sec:problem}


% \sweExpl{svensk: Problemdefinition eller Frågeställning\\
% Lyft fram det ursprungliga problemet om det finns något och definiera därefter
% den ingenjörsmässiga erfarenheten eller/och vetenskapen som kan komma ur
% projektet. }


Large Language Models (LLMs) have gained widespread use since its popularisation by ChatGPT. Their abilities to summarise large bodies of text and follow user instructions have proven very useful in many contexts. However, considering their limited context window (and drawbacks of models with larger context window \cite{liu_lost_2023}) deploying useful applications with a chat based interface still rely upon integrating a RAG system, introduced by Lewis et al. \cite{lewis_retrieval-augmented_2021}. These can retrieve relevant information needed to answer a user's query from outside data sources and inject them into the conversation.


Some unreleased models, such as the gemini family of models \cite{gemini_team_gemini_2023}, have been reported to show great recall performance and reasoning abilities over millions of tokens. This could significantly reduce the importance of RAG systems in applications which utilise LLMs and external datasets to create intelligent systems with domain specific knowledge. However, even though no exact figures are presented by the Gemini time, inference speed (the time taken to produce a response to a prompt) seems to be significantly slower than shorter contexts. This would again highlight the importance of efficient RAG systems. Still, other approaches than traditional GPUs have been shown recently \cite{abts_software-defined_2022} by the Groq team to greatly increase inference speed.


% remember to update to this ref
% @techreport{Gemini15Report2024,
%   title = {Gemini 1.5: Unlocking Multimodal Understanding Across Millions of Tokens of Context},
%   author = {The Gemini Team},
%   year = {2024},
%   institution = {Google},
%   note = {Available: \url{https://research.google/pubs/pub50446/}},
%   abstract = {In this report, we present the latest model of the Gemini family, Gemini 1.5 Pro, a highly compute-efficient multimodal mixture-of-experts model capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio.}
% }


Evaluating large language models is notoriously difficult. There are objective and automated metrics that can be used for tasks such as evaluating a model's summarisation capabilities, as shown by Basyal and Sanghvi \cite{basyal_text_2023}. However, for more complicated evaluations it gets trickier. In their seminal instructGPT paper Ouyang et al. at OpenAI try to evaluate \textit{“how well a model can follow instructions”} \cite{ouyang_training_2022} which is a very subjective question. They essentially relied upon human labelers to judge the overall quality of each response generated by the model.


In their Gemini-paper the Gemini team discuss the benchmarks used for their largest model. The team states that benchmarks are often designed to test shorter prompts whereas their longer prompts challenge tests used in traditional evaluation methods that rely heavily on manual evaluation. This highlights the relevance of good evaluation metrics. Regardless of context size or inference speed, evaluation of models tends to be very general. Which makes sense, when considering their general application.


When releasing their Mixtral model \cite{jiang_mixtral_2024} the Mistral AI team used a range of benchmark tests, such as MMLU, PIQA, GSM8K etc. MMLU (\textit{Measuring Massive Multitask Language Understanding}) \cite{hendrycks_measuring_2021} benchmarks a LLMs proficiency in understanding and reasoning across various subjects such as humanities, STEM, and professional and everyday knowledge, by evaluating its performance on 57 tasks, to test its ability to generalise and apply knowledge. PIQA (\textit{Physical Interaction: Question Answering}) \cite{bisk_piqa_2019}, evaluates a language models understanding of physical commonsense by asking them to predict the outcome of physical interactions in various scenarios through multiple-choice questions. GSM8K (\textit{The Grade School Math}) \cite{cobbe_training_2021} tests the ability to solve elementary-level mathematics word problems.


Evaluation of how well LLMs perform is an open research question. As shown above LLM developers often utilise multiple testsuites. These are oftentimes, as shown above, very general tests. When implementing LLMs in practical applications good performance often relies upon very good raw summarisation performance and reasoning abilities. Since the domain specific knowledge is provided to the model, raw built-in knowledge isn’t crucial. It is more important for the model to learn the task at hand using very few examples and within the given domain understand the question being asked by a user.
Further, as argued by by Siriwardhana et al., the training data of LLMs include the knowledge of datasets such as Wikipedia \cite{siriwardhana_improving_2023} which means that evaluation methods in very specialised domains hold higher value than generalised domains. These brand new domains, that with certainty haven't been seen during training, tests the models zero-shot, and depending on the implementation, few-shot learning abilities.


The research question for this project is \textit{Which language model and which retrieval techniques do students prefer using?} and \textit{Is it possible to deploy an AI-assistant using a completely open source toolchain?}.


I believe the answer to the first question is that the closed source alternatives will be preferred by the students, however, I think the results will show it is possible to deploy an open source based AI assistant too.


\subsection{Original problem and definition}
\label{sec:researchQuestion}


% \sweExpl{Ursprungligt problem och definition}
% Some text


% \subsection{Scientific and engineering issues}\sweExpl{Vetenskaplig och ingenjörsmässig frågeställning}
% some text


The core challenge addressed in this thesis is the effective deployment and evaluation of AI-assistants powered by \gls{LLM} and \gls{RAG} techniques in a specialised domain, specifically within the \gls{LMS} of Canvas course rooms at KTH. This involves assessing the practicality and efficiency of integrating AI-Assistants built upon LLMs and RAG techniques into the educational settings to aid in reducing administrative burdens on educators and enhancing student interaction with course materials.


The original problem stems from the need to understand whether AI-assistants can effectively handle the domain-specific data intrinsic to educational platforms that are not included in their initial training datasets. Furthermore, the project aims to compare the efficacy and acceptability of open-source versus proprietary AI models in real-world educational applications.


\section{Purpose}


% \sweExpl{Syfte}
% \sweExpl{Skilj på syfte och mål! Syfte är att förändra något till det bättre. I examensarbetet finns ofta två aspekter på detta. Dels vill problemägaren (företaget) få sitt problem löst till det bättre men akademin och ingenjörssamfundet vill också få nya erfarenheter och vetskap. Beskriv ett syfte som tillfredställer båda dessa aspekter.\\
% Det finns även ett syfte till som kan vara värt att beakta och det är att du som student skall ta examen och att du måste bevisa, i ditt examensarbete, att du uppfyller examensmålen. Dessa mål sammanfaller med kursmålen för examensarbetskursen.
% }
% \generalExpl{State the purpose of your thesis and the purpose of your degree project.\\
% Describe who benefits and how they benefit if you achieve your goals. Include anticipated ethical, sustainability, social issues, etc. related to your project. (Return to these in your reflections in Section~\ref{sec:reflections}.)}


The purpose of this thesis is two-fold: firstly, to innovate within the educational technology space by integrating AI-assistants to potentially reduce workload and improve informational access within Canvas course rooms. Secondly, the thesis aims to contribute to academic knowledge by providing empirical data on the performance of these AI systems in a controlled educational setting. This dual purpose ensures the project not only addresses the immediate needs of KTH's digital learning environment but also enriches the scientific community’s understanding of applied AI in education.[a]


This research is intended to benefit educational institutions by potentially offering a tool that improves operational efficiency and students by providing an alternative, possibly more effective way of interacting with course content. In addition the research will bring benefit for researchers within AI and education. Ethically, the study focuses on the sustainable development of AI technologies by emphasising open-source solutions, aiming to democratise advanced technological developments and reduce reliance on proprietary models.




\section{Goals}
\label{sec:goals}


% \sweExpl{Mål}
% \sweExpl{Skilj på syfte och mål. Syftet är att åstakomma en förändring i något. Målen är vad som konkret skall göras för att om möjligt uppnå den önskade förändringen (syfte). }


% \generalExpl{State the goal/goals of this degree project.}


%The goal of this project is XXX. This has been divided into the following three sub-goals:
%\begin{enumerate}
%\item Subgoal 1 % \sweExpl{för att tillfredsställa problemägaren – industrin?}
%\item Subgoal 2 % \sweExpl{för att tillfredsställa ingenjörssamfundet och vetenskapen – akademin) }
%\item Subgoal 3 % \sweExpl{eventuellt, för att uppfylla kursmålen – du som student}
%\end{enumerate}


The goals of this degree project are organised to comprehensively assess the deployment of AI-assistants within the educational framework of KTH's Canvas LMS, focusing on technological effectiveness and user receptiveness:[b]


\begin{enumerate}
        \item \textbf{Technological Efficacy:} To evaluate the accuracy, speed, and reliability of responses by AI-assistants utilising both proprietary and open-source models in handling domain-specific content.
        \item \textbf{User Preference:} To ascertain the preferences of different user groups (students, faculty) regarding the usability, information quality, and overall experience of interacting with various AI-assistant models and retrieval techniques.
        \item \textbf{Operational Feasibility:} To assess the feasibility of integrating a fully open-source AI-assistant within an academic setting, considering logistical, technical, and regulatory constraints.
        \item \textbf{Educational Impact:} To explore the potential of AI-assistants to reduce administrative burdens on educators and improve information accessibility for students.
        \item \textbf{Comparative Analysis:} To perform a comparative study between open-source and proprietary models concerning their deployment costs, maintenance needs, and infrastructure requirements.
\end{enumerate}


Each goal is designed to address a specific aspect of AI technology integration within educational practices, ensuring that the project outcomes are relevant and useful for both academic research and educational administration.




% \generalExpl{In addition to presenting the goal(s), you might also state what the deliverables and results of the project are.}


\section{Research Methodology}
\label{sec:research_methodology}


% \sweExpl{Undersökningsmetod}
% \sweExpl{Här anger du vilken vilken övergripande undersökningsstrategi eller metod du skall använda för att försöka besvara den akademiska frågeställning och samtidigt lösa det e v ursprungliga problemet. Ofta kan man använda ”lösandet av ursprungsproblemet” som en fallstudie kring en akademisk frågeställning. Du undersöker någon intressant fråga i ”skarpt” läge och samlar resultat och erfarenhet ur detta.\\
% Tänk på att företaget ibland måste stå tillbaka i sin önskan och förväntan på projektets resultat till förmån för ny eller kompletterande ingenjörserfarenhet och vetenskap (ditt examensarbete). Det är du som student som bestämmer och löser fördelningen mellan dessa två intressen men se till att alla är informerade. }
% \generalExpl{Introduce your choice of methodology/methodologies and method/methods – and the reason why you chose them. Contrast them with and explain why you did not choose other methodologies or methods. (The details of the actual methodology and method you have chosen will be given in Chapter~\ref{ch:methods}. Note that in Chapter~\ref{ch:methods}, the focus could be research strategies, data collection, data analysis, and quality assurance.)\\
% In this section you should present your philosophical assumption(s), research method(s), and research approach(es).}


This project employs a hybrid research methodology combining empirical data collection with qualitative insights to evaluate the implementation of AI-assistants in an educational setting effectively:


\subsection{System Design and Implementation}
\begin{description}
        \item[Model Selection] Different models, including proprietary and open-source, with different training data/methods, will be evaluated to determine their performance in educational environments.
        \item[RAG Integration] Various configurations of Retrieval Augmented Generation systems will be tested to identify the most effective method for enhancing the AI's responses with relevant information from KTH’s course-specific data.
\end{description}


\subsection{Evaluation Design}
\begin{description}
        \item[Study Participants] The study will involve students using the AI-assistant and providing feedback on their experiences. There are various types of students participating in the study.
        \item[Experimental Setup] Controlled experiments will be conducted where participants use different configurations of the AI-assistant for typical student questions.
        \item[Data Collection Methods] Data will be collected through integrated survey tools within the chat interface, capturing real-time feedback on the AI-assistant’s performance and student satisfaction.
\end{description}


\subsection{Analysis Techniques}
\begin{description}
        \item[Quantitative Analysis] Statistical methods will analyse usage data and response accuracy to quantitatively assess the AI-assistant's performance.
        \item[Qualitative Analysis] Feedback and open-ended responses will be analysed textually to understand user perceptions and contextual effectiveness of the AI-assistant.
\end{description}


This methodology was chosen for its ability to provide a comprehensive evaluation of both the technical capabilities and the practical usability of AI-assistants, offering insights into their potential benefits and limitations in the specific context for this study.




\section{Delimitations}
\label{sec:delimitations}


% \generalExpl{Describe the boundary/limits of your thesis project and what you are explicitly not going to do. This will help you bound your efforts – as you have clearly defined what is out of the scope of this thesis project. Explain the delimitations. These are all the things that could affect the study if they were examined and included in the degree project.}


This project has several delimitations that define the scope and boundaries of the research to ensure a focused and manageable study. The key delimitations are;


\begin{itemize}
        \item \textbf{Model Scope:} The project will not involve the development of new models or the fine-tuning of existing models. This includes LLMs and embedding functions. The study will utilise pre-trained models offered by bigger vendors or the open source community.
        \item \textbf{Data Limitations:} Only existing courses within KTH’s Canvas LMS will be utilised for the study. No new course content will be created, and no modifications will be made to existing course materials beyond what is necessary for the integration and testing of the AI-assistants.
        \item \textbf{Course Data Access:} The project will not use Canvas APIs for data integration. All interactions with the Canvas platform will be through existing interfaces, or data will be scraped and used from the Canvas web interface.
        \item \textbf{Geographic and Cultural Constraints:} The study is limited to the KTH environment, which may not represent other educational settings in different cultural or geographic contexts. The findings might not be directly transferable to other institutions or countries without additional localization and adaptation.[c]
\end{itemize}[d]


These delimitations are set to clarify the focus of the research and define what is outside the scope of this thesis project. They help in managing expectations and provide a clear framework within which the study operates.






\section{Structure of the thesis}


% \sweExpl{ Rapportens disposition}


Chapter~\ref{ch:background} presents relevant background information about xxx.  Chapter~\ref{ch:methods} presents the methodology and method used to solve the problem. …


\cleardoublepage


[a]formulera om
[b]formulera om?
[c]expand upon this
[d]maybe add more here?